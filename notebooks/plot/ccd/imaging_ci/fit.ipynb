{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots CCD: Fit\n",
        "==============\n",
        "\n",
        "CTI calibration is typically performed on a CCD using many images (8-32 or more), where the images vary in the level of\n",
        "charge injected into the CCD (the charge injection level).\n",
        "\n",
        "Visualizing the results of a CTI calibration in a way that shows the results across all injection levels is\n",
        "challenging, as there is a lot of information to convey.\n",
        "\n",
        "The `autocti_workspace/*/plot/ccd` package provides tools for simulating CTI calibration data, fitting it in a realistic\n",
        "calibration setting and plotting the results of the fit.\n",
        "\n",
        "__Fit__\n",
        "\n",
        "This script fits the simulated CTI calibration data simulated in the `plot/ccd/imaging_ci/simulator.py` script. It\n",
        "outputs visuals which summarize the results of the fit concise in a single matplotlib figure, in particular:\n",
        "\n",
        " - An image of the datasets and fits to all 32 simulated datasets, where these are group in columns of the 4 different\n",
        "   quadrants across the 8 different charge injection levels.\n",
        "\n",
        " - The same figure above but for the FPRs and EPERs only.\n",
        "\n",
        "These images are both output to hard-disk as .png files during the model-fit and shown how to output via a\n",
        "`Plotter` object at the end of the script.\n",
        "\n",
        "__Database__\n",
        "\n",
        "The visuals output in this script are created be rerunning the model-fit from the results on the hard-disk. This can\n",
        "make replotting visuals and customizing the appearance of plots straight forward cumbersome and slow.\n",
        "\n",
        "The script `plot/ccd/imaging_ci/database.py` shows how to load the results of the fit performed here via an .sqlite\n",
        "database, which is a convenient and efficient way to produce these visuals.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits a 1D dataset with CTI, where:\n",
        "\n",
        " - CTI is added to the image using a 1 `Trap` species model.\n",
        " - The volume filling behaviour in the direction uses the `CCD` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autocti as ac\n",
        "import autocti.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load the CTI dataset 'imaging_ci/simple' 'from .fits files, which is the dataset we will use to perform CTI modeling.\n",
        "\n",
        "You should be familiar with how we load datasets in this way, if not checkout the `overview` \n",
        "and `modeling/start_here.py` examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"imaging_ci\"\n",
        "\n",
        "shape_native = (100, 100)\n",
        "\n",
        "parallel_overscan = ac.Region2D((95, 100, 5, 95))\n",
        "serial_prescan = ac.Region2D((0, 100, 0, 5))\n",
        "serial_overscan = ac.Region2D((0, 95, 95, 100))\n",
        "\n",
        "region_list = [\n",
        "    (5, 25, serial_prescan[3], serial_overscan[2]),\n",
        "]\n",
        "\n",
        "norm_list = [100, 500, 1000, 5000, 10000, 25000, 100000, 200000]\n",
        "total_datasets = len(norm_list)\n",
        "\n",
        "dataset_list = []\n",
        "dataset_full_list = []\n",
        "\n",
        "settings_dict = {\n",
        "    \"CCD\": f\"1-1.E\",\n",
        "    \"IJON\": 214,\n",
        "    \"IJOFF\": 200,\n",
        "    \"IDDLY\": np.round(0.001536, 5),\n",
        "    \"IG1\": np.round(4.2500439453125, 3),\n",
        "    \"IG2\": np.round(6.0028662109375, 3),\n",
        "}\n",
        "\n",
        "for norm in norm_list:\n",
        "    for quadrant_id in range(4):\n",
        "        dataset_name = f\"data_quad_{quadrant_id}\"\n",
        "        dataset_path = path.join(\"dataset\", dataset_type, \"ccd_plot\", dataset_name)\n",
        "\n",
        "        layout = ac.Layout2DCI(\n",
        "            shape_2d=shape_native,\n",
        "            region_list=region_list,\n",
        "            parallel_overscan=parallel_overscan,\n",
        "            serial_prescan=serial_prescan,\n",
        "            serial_overscan=serial_overscan,\n",
        "        )\n",
        "\n",
        "        dataset_quad = ac.ImagingCI.from_fits(\n",
        "            data_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"data.fits\"),\n",
        "            noise_map_path=path.join(\n",
        "                dataset_path, f\"norm_{int(norm)}\", \"noise_map.fits\"\n",
        "            ),\n",
        "            pre_cti_data_path=path.join(\n",
        "                dataset_path, f\"norm_{int(norm)}\", \"pre_cti_data.fits\"\n",
        "            ),\n",
        "            layout=layout,\n",
        "            pixel_scales=0.1,\n",
        "            settings_dict=settings_dict,\n",
        "        )\n",
        "\n",
        "        dataset_full_quad = ac.ImagingCI.from_fits(\n",
        "            data_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"data.fits\"),\n",
        "            noise_map_path=path.join(\n",
        "                dataset_path, f\"norm_{int(norm)}\", \"noise_map.fits\"\n",
        "            ),\n",
        "            pre_cti_data_path=path.join(\n",
        "                dataset_path, f\"norm_{int(norm)}\", \"pre_cti_data.fits\"\n",
        "            ),\n",
        "            layout=layout,\n",
        "            pixel_scales=0.1,\n",
        "            settings_dict=settings_dict,\n",
        "        )\n",
        "\n",
        "        mask = ac.Mask2D.all_false(\n",
        "            shape_native=dataset_quad.shape_native,\n",
        "            pixel_scales=dataset_quad.pixel_scales,\n",
        "        )\n",
        "\n",
        "        mask = ac.Mask2D.masked_fpr_and_eper_from(\n",
        "            mask=mask,\n",
        "            layout=dataset_quad.layout,\n",
        "            settings=ac.SettingsMask2D(parallel_fpr_pixels=(0, 20)),\n",
        "            pixel_scales=dataset_quad.pixel_scales,\n",
        "        )\n",
        "\n",
        "        dataset_quad = dataset_quad.apply_mask(mask=mask)\n",
        "\n",
        "        dataset_list += [dataset_quad]\n",
        "        dataset_full_list += [dataset_full_quad]\n",
        "\n",
        "clocker = ac.Clocker2D(\n",
        "    parallel_express=5,\n",
        "    parallel_roe=ac.ROEChargeInjection(),\n",
        ")\n",
        "\n",
        "parallel_trap_0 = af.Model(ac.TrapInstantCapture)\n",
        "\n",
        "parallel_trap_list = [parallel_trap_0]\n",
        "\n",
        "parallel_ccd = af.Model(ac.CCDPhase)\n",
        "parallel_ccd.well_notch_depth = 0.0\n",
        "parallel_ccd.full_well_depth = 200000.0\n",
        "\n",
        "model = af.Collection(\n",
        "    cti=af.Model(\n",
        "        ac.CTI2D, parallel_trap_list=parallel_trap_list, parallel_ccd=parallel_ccd\n",
        "    )\n",
        ")\n",
        "\n",
        "search = af.DynestyStatic(\n",
        "    path_prefix=path.join(\"plot_ccd\", \"imaging_ci\"), name=\"ccd_8x4\", nlive=50\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    ac.AnalysisImagingCI(dataset=dataset, clocker=clocker, dataset_full=dataset_full)\n",
        "    for dataset, dataset_full in zip(dataset_list, dataset_full_list)\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "analysis.n_cores = 1\n",
        "\n",
        "result_list = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Plotting__\n",
        "\n",
        "The model-fit above creates images of summarizing the fit over the 32 CCD / quadrant images in the `image` folder.\n",
        "This includes fits of all 32 images, residuals and zoom ins on the FPR and EPERs regions.\n",
        "\n",
        "The results above return a result_list, which consists of the model-fit to the 32 (8 charge injection regions x 4\n",
        "quadrants) individual datasets. This can be used to separately reproduce these visuals.\n",
        "\n",
        "The example below shows how we can create a plot of the EPER trails of all 32 datasets, using the `FitImagingCIPlotter`\n",
        "and a `MultiFigurePlotter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_list = [result.max_log_likelihood_fit for result in result_list]\n",
        "\n",
        "mat_plot = aplt.MatPlot1D(\n",
        "    output=aplt.Output(path=path.join(\"scripts\", \"plot\", \"images\"), format=\"png\")\n",
        ")\n",
        "\n",
        "fit_plotter_list = [\n",
        "    aplt.FitImagingCIPlotter(\n",
        "        fit=fit,\n",
        "        mat_plot_1d=mat_plot,\n",
        "    )\n",
        "    for fit in fit_list\n",
        "]\n",
        "multi_plotter = aplt.MultiFigurePlotter(plotter_list=fit_plotter_list)\n",
        "\n",
        "multi_plotter.subplot_of_figure(\n",
        "    func_name=\"figures_1d\", figure_name=\"data\", region=\"parallel_eper\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Database__\n",
        "\n",
        "Creating custom figures as above is somewhat cumbersome, as it requires us to rerun the model-fit, load the results,\n",
        "and create the plotter and figure for each dataset.\n",
        "\n",
        "The example `plots/imaging_ci/database.py` shows how we can use the database to load the results of the model-fit\n",
        "and create the figure above in a single line of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}