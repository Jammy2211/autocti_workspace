{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Fits\n",
        "=============\n",
        "\n",
        "This tutorial inspects the model's fit to the data using the `FitDataset1D` object inferred by the non-linear search, \n",
        "for example visualizing and interpreting its results.\n",
        "\n",
        "This includes inspecting the residuals, chi-squared and other goodness-of-fit quantities.\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the **PyAutoCTI** plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autocti_workspace/*/plot` package in full. This \n",
        "includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutorial.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoCTI**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autocti as ac\n",
        "import autocti.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "The code below performs a model-fit using nautilus. \n",
        "\n",
        "You should be familiar with modeling already, if not read the `modeling/start_here.py` script before reading this one!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"dataset_1d\", dataset_name)\n",
        "\n",
        "shape_native = (200,)\n",
        "\n",
        "prescan = ac.Region1D(region=(0, 10))\n",
        "overscan = ac.Region1D(region=(190, 200))\n",
        "\n",
        "region_list = [(10, 20)]\n",
        "\n",
        "norm_list = [100, 5000, 25000, 200000]\n",
        "\n",
        "total_datasets = len(norm_list)\n",
        "\n",
        "layout_list = [\n",
        "    ac.Layout1D(\n",
        "        shape_1d=shape_native,\n",
        "        region_list=region_list,\n",
        "        prescan=prescan,\n",
        "        overscan=overscan,\n",
        "    )\n",
        "    for i in range(total_datasets)\n",
        "]\n",
        "\n",
        "dataset_list = [\n",
        "    ac.Dataset1D.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"data.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"noise_map.fits\"),\n",
        "        pre_cti_data_path=path.join(\n",
        "            dataset_path, f\"norm_{int(norm)}\", \"pre_cti_data.fits\"\n",
        "        ),\n",
        "        layout=layout,\n",
        "        pixel_scales=0.1,\n",
        "    )\n",
        "    for layout, norm in zip(layout_list, norm_list)\n",
        "]\n",
        "\n",
        "mask = ac.Mask1D.all_false(\n",
        "    shape_slim=dataset_list[0].shape_slim,\n",
        "    pixel_scales=dataset_list[0].pixel_scales,\n",
        ")\n",
        "\n",
        "mask = ac.Mask1D.masked_fpr_and_eper_from(\n",
        "    mask=mask,\n",
        "    layout=dataset_list[0].layout,\n",
        "    settings=ac.SettingsMask1D(fpr_pixels=(0, 10)),\n",
        "    pixel_scales=dataset_list[0].pixel_scales,\n",
        ")\n",
        "\n",
        "dataset_list = [dataset.apply_mask(mask=mask) for dataset in dataset_list]\n",
        "\n",
        "clocker = ac.Clocker1D(express=5)\n",
        "\n",
        "trap_0 = af.Model(ac.TrapInstantCapture)\n",
        "trap_1 = af.Model(ac.TrapInstantCapture)\n",
        "\n",
        "trap_0.add_assertion(trap_0.release_timescale < trap_1.release_timescale)\n",
        "\n",
        "trap_list = [trap_0, trap_1]\n",
        "\n",
        "ccd = af.Model(ac.CCDPhase)\n",
        "ccd.well_notch_depth = 0.0\n",
        "ccd.full_well_depth = 200000.0\n",
        "\n",
        "model = af.Collection(cti=af.Model(ac.CTI1D, trap_list=trap_list, ccd=ccd))\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"dataset_1d\", dataset_name), name=\"species[x2]\", n_live=100\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    ac.AnalysisDataset1D(dataset=dataset, clocker=clocker) for dataset in dataset_list\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "result_list = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Max Likelihood Fit__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_fit` which we can visualize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = result_list[0].max_log_likelihood_fit\n",
        "\n",
        "fit_plotter = aplt.FitDataset1DPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit Quantities__\n",
        "\n",
        "The maximum log likelihood fit contains many 1D and 2D arrays showing the fit.\n",
        "\n",
        "These use the `slim` and `native` API discussed in the previous results tutorial.\n",
        "\n",
        "There is a `model_image`, which is the image of the plane we inspected in the previous tutorial blurred with the \n",
        "imaging data's PSF. \n",
        "\n",
        "This is the image that is fitted to the data in order to compute the log likelihood and therefore quantify the \n",
        "goodness-of-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_data.slim)\n",
        "print(fit.model_data.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are numerous ndarrays showing the goodness of fit: \n",
        "\n",
        " - `residual_map`: Residuals = (Data - Model_Data).\n",
        " - `normalized_residual_map`: Normalized_Residual = (Data - Model_Data) / Noise\n",
        " - `chi_squared_map`: Chi_Squared = ((Residuals) / (Noise)) ** 2.0 = ((Data - Model)**2.0)/(Variances)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.residual_map.slim)\n",
        "print(fit.residual_map.native)\n",
        "\n",
        "print(fit.normalized_residual_map.slim)\n",
        "print(fit.normalized_residual_map.native)\n",
        "\n",
        "print(fit.chi_squared_map.slim)\n",
        "print(fit.chi_squared_map.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Figures of Merit__\n",
        "\n",
        "There are single valued floats which quantify the goodness of fit:\n",
        "\n",
        " - `chi_squared`: The sum of the `chi_squared_map`.\n",
        " - `noise_normalization`: The normalizing noise term in the likelihood function \n",
        "    where [Noise_Term] = sum(log(2*pi*[Noise]**2.0)).\n",
        " - `log_likelihood`: The log likelihood value of the fit where [LogLikelihood] = -0.5*[Chi_Squared_Term + Noise_Term]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.chi_squared)\n",
        "print(fit.noise_normalization)\n",
        "print(fit.log_likelihood)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "In this tutorial, we saw how to inspect the quality of a model fit using the fit imaging object.\n",
        "\n",
        "If you are modeling galaxies using interferometer data we cover the corresponding fit object in tutorial 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}