{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: CTI\n",
        "============"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autocti as ac\n",
        "import autocti.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "The code below performs a model-fit using nautilus. \n",
        "\n",
        "You should be familiar with modeling already, if not read the `modeling/start_here.py` script before reading this one!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"dataset_1d\", dataset_name)\n",
        "\n",
        "shape_native = (200,)\n",
        "\n",
        "prescan = ac.Region1D(region=(0, 10))\n",
        "overscan = ac.Region1D(region=(190, 200))\n",
        "\n",
        "region_list = [(10, 20)]\n",
        "\n",
        "norm_list = [100, 5000, 25000, 200000]\n",
        "\n",
        "total_datasets = len(norm_list)\n",
        "\n",
        "layout_list = [\n",
        "    ac.Layout1D(\n",
        "        shape_1d=shape_native,\n",
        "        region_list=region_list,\n",
        "        prescan=prescan,\n",
        "        overscan=overscan,\n",
        "    )\n",
        "    for i in range(total_datasets)\n",
        "]\n",
        "\n",
        "dataset_list = [\n",
        "    ac.Dataset1D.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"data.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"noise_map.fits\"),\n",
        "        pre_cti_data_path=path.join(\n",
        "            dataset_path, f\"norm_{int(norm)}\", \"pre_cti_data.fits\"\n",
        "        ),\n",
        "        layout=layout,\n",
        "        pixel_scales=0.1,\n",
        "    )\n",
        "    for layout, norm in zip(layout_list, norm_list)\n",
        "]\n",
        "\n",
        "mask = ac.Mask1D.all_false(\n",
        "    shape_slim=dataset_list[0].shape_slim,\n",
        "    pixel_scales=dataset_list[0].pixel_scales,\n",
        ")\n",
        "\n",
        "mask = ac.Mask1D.masked_fpr_and_eper_from(\n",
        "    mask=mask,\n",
        "    layout=dataset_list[0].layout,\n",
        "    settings=ac.SettingsMask1D(fpr_pixels=(0, 10)),\n",
        "    pixel_scales=dataset_list[0].pixel_scales,\n",
        ")\n",
        "\n",
        "dataset_list = [dataset.apply_mask(mask=mask) for dataset in dataset_list]\n",
        "\n",
        "clocker = ac.Clocker1D(express=5)\n",
        "\n",
        "trap_0 = af.Model(ac.TrapInstantCapture)\n",
        "trap_1 = af.Model(ac.TrapInstantCapture)\n",
        "\n",
        "trap_0.add_assertion(trap_0.release_timescale < trap_1.release_timescale)\n",
        "\n",
        "trap_list = [trap_0, trap_1]\n",
        "\n",
        "ccd = af.Model(ac.CCDPhase)\n",
        "ccd.well_notch_depth = 0.0\n",
        "ccd.full_well_depth = 200000.0\n",
        "\n",
        "model = af.Collection(cti=af.Model(ac.CTI1D, trap_list=trap_list, ccd=ccd))\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"dataset_1d\", dataset_name), name=\"species[x2]\", n_live=100\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    ac.AnalysisDataset1D(dataset=dataset, clocker=clocker) for dataset in dataset_list\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "result_list = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "\n",
        "samples = result_list[0].samples\n",
        "\n",
        "\n",
        "delta_ellipticity_list = []\n",
        "\n",
        "print(samples.model.info)\n",
        "\n",
        "for sample in samples.sample_list:\n",
        "    instance = sample.instance_for_model(model=samples.model, ignore_assertions=True)\n",
        "    delta_ellipticity_list.append(instance.cti.delta_ellipticity)\n",
        "\n",
        "(\n",
        "    median_delta_ellipticity,\n",
        "    upper_delta_ellipticity,\n",
        "    lower_delta_ellipticity,\n",
        ") = af.marginalize(\n",
        "    parameter_list=delta_ellipticity_list,\n",
        "    sigma=2.0,\n",
        "    weight_list=samples.weight_list,\n",
        ")\n",
        "\n",
        "print(median_delta_ellipticity)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}