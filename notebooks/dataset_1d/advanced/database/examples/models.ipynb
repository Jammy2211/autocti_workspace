{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Database: Models\n",
        "================\n",
        "\n",
        "In this tutorial, we use the database to load models and `CTI` objects from a non-linear search. This allows us to\n",
        "visualize and interpret its results.\n",
        "\n",
        "We then show how the database also allows us to load many `CTI` objects correspond to many samples of the non-linear\n",
        "search. This allows us to compute the errors on quantities that the `CTI` object contains, but were not sampled\n",
        "directly by the non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autofit as af\n",
        "import autocti as ac\n",
        "import autocti.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Database File__\n",
        "\n",
        "First, set up the aggregator as we did in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator.from_database(\"database.sqlite\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__CTI via Database__\n",
        "\n",
        "Having performed a model-fit, we now want to interpret and visualize the results. In this example, we want to inspect\n",
        "the `CTI` objects that gave good fits to the data. \n",
        "\n",
        "Using the API shown in the `start_here.py` example this would require us to create a `Samples` object and manually \n",
        "compose our own `CTI` object. For large datasets, this would require us to use generators to ensure it is memory-light,\n",
        "which are cumbersome to write.\n",
        "\n",
        "This example therefore uses the `CTIAgg` object, which conveniently loads the `CTI` objects of every fit via \n",
        "generators for us. Explicit examples of how to do this via generators is given in the `advanced/manual_generator.py` \n",
        "tutorial.\n",
        "\n",
        "We get a CTI generator via the `ac.agg.CTIAgg` object, where this `cti_gen` contains the maximum log\n",
        "likelihood `CTI `object of every model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cti_agg = ac.agg.CTIAgg(aggregator=agg)\n",
        "cti_gen = cti_agg.max_log_likelihood_gen_from()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now iterate over our `CTI `object generator to make the plots we desire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for cti in cti_gen:\n",
        "    print(cti)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__CTI Delta Ellipticity Requirement__\n",
        "\n",
        "Each `CTI `object can inform us, based on its error, what the induced spurious ellipticity on galaxy shape \n",
        "measurements is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cti_gen = cti_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "print(\"Maximum Log Likelihood Spurious Ellipticity:\")\n",
        "\n",
        "for cti in cti_gen:\n",
        "    delta_ellipticity = cti.delta_ellipticity\n",
        "\n",
        "    print(\"Delta Ellipticity = \", delta_ellipticity)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors (PDF from samples)__\n",
        "\n",
        "In this example, we will compute the errors on the delta ellipticity of a model. Computing the errors on a quantity \n",
        "like the trap `density` is simple, because it is sampled by the non-linear search. The errors are therefore accessible\n",
        "via the `Samples`, by marginalizing over all over parameters via the 1D Probability Density Function (PDF).\n",
        "\n",
        "Computing the errors on the delta ellipticity is more tricky, because it is a derived quantity. It is a parameter or \n",
        "measurement that we want to calculate but was not sampled directly by the non-linear search. The `CTIAgg` object \n",
        "object has everything we need to compute the errors of derived quantities.\n",
        "\n",
        "Below, we compute the delta ellipticity of every model sampled by the non-linear search and use this determine the PDF \n",
        "of the delta ellipticity. When combining each delta ellipticity we weight each value by its `weight`. For Nautilus, \n",
        "the nested sampler used by the fit, this ensures models which gave a bad fit (and thus have a low weight) do not \n",
        "contribute significantly to the delta ellipticity error estimate.\n",
        "\n",
        "We set `minimum_weight=`1e-4`, such that any sample with a weight below this value is discarded when computing the \n",
        "error. This speeds up the error computation by only using a small fraction of the total number of samples. Computing\n",
        "a delta ellipticity is cheap, and this is probably not necessary. However, certain quantities have a non-negligible\n",
        "computational overhead is being calculated and setting a minimum weight can speed up the calculation without \n",
        "significantly changing the inferred errors.\n",
        "\n",
        "Below, we use the `CTIAgg` object to get the `CTI` object of every Nautilus sample in each model-fit. We extract from \n",
        "each `CTI `object the model's delta ellipticity, store them in a list and find the value via the PDF and quantile \n",
        "method. This again uses generators, ensuring minimal memory use. \n",
        "\n",
        "In order to use these samples in the function `quantile`, we also need the weight list of the sample weights. We \n",
        "compute this using the ``CTIAgg`'s function `weights_above_gen_from`, which computes generators of the weights of \n",
        "all points above this minimum value. This again ensures memory use in minimal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cti_agg = ac.agg.CTIAgg(aggregator=agg)\n",
        "cti_list_gen = cti_agg.all_above_weight_gen_from(minimum_weight=1e-4)\n",
        "weight_list_gen = cti_agg.weights_above_gen_from(minimum_weight=1e-4)\n",
        "\n",
        "for cti_gen, weight_gen in zip(cti_list_gen, weight_list_gen):\n",
        "    delta_ellipticity_list = []\n",
        "\n",
        "    for cti in cti_gen:\n",
        "        delta_ellipticity = cti.delta_ellipticity\n",
        "\n",
        "        delta_ellipticity_list.append(delta_ellipticity)\n",
        "\n",
        "    weight_list = [weight for weight in weight_gen]\n",
        "\n",
        "    try:\n",
        "        (\n",
        "            median_delta_ellipticity,\n",
        "            upper_delta_ellipticity,\n",
        "            lower_delta_ellipticity,\n",
        "        ) = af.marginalize(\n",
        "            parameter_list=delta_ellipticity_list, sigma=2.0, weight_list=weight_list\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"delta ellipticity = {median_delta_ellipticity} ({upper_delta_ellipticity} {lower_delta_ellipticity}\"\n",
        "        )\n",
        "    except IndexError:\n",
        "        pass"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors (Random draws from PDF)__\n",
        "\n",
        "An alternative approach to estimating the errors on a derived quantity is to randomly draw samples from the PDF \n",
        "of the non-linear search. For a sufficiently high number of random draws, this should be as accurate and precise\n",
        "as the method above. However, it can be difficult to be certain how many random draws are necessary.\n",
        "\n",
        "The weights of each sample are used to make every random draw. Therefore, when we compute the delta ellipticity and its \n",
        "errors we no longer need to pass the `weight_list` to the `quantile` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cti_agg = ac.agg.CTIAgg(aggregator=agg)\n",
        "cti_list_gen = cti_agg.randomly_drawn_via_pdf_gen_from(total_samples=2)\n",
        "\n",
        "for cti_gen in cti_list_gen:\n",
        "    delta_ellipticity_list = []\n",
        "\n",
        "    for cti in cti_gen:\n",
        "        delta_ellipticity = cti.delta_ellipticity\n",
        "\n",
        "        delta_ellipticity_list.append(delta_ellipticity)\n",
        "\n",
        "    (\n",
        "        median_delta_ellipticity,\n",
        "        upper_delta_ellipticity,\n",
        "        lower_delta_ellipticity,\n",
        "    ) = af.marginalize(parameter_list=delta_ellipticity_list, sigma=3.0)\n",
        "\n",
        "    print(\n",
        "        f\"delta ellipticity = {median_delta_ellipticity} ({upper_delta_ellipticity} {lower_delta_ellipticity}\"\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}