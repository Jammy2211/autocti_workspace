{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correction: Start Here\n",
        "======================\n",
        "\n",
        "In this script, we correct CTI from a 1D CTI calibration dataset using a known CTI model.\n",
        "\n",
        "Whilst correcting CTI calibration data is not something one would commonly do, this script is here to illustrate\n",
        "the API for performing CTI correction.\n",
        "\n",
        "The correction of CTI calibration data can also be used as a diagnostic for the quality of the CTI model that is\n",
        "calibrated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import json\n",
        "from os import path\n",
        "import autocti as ac\n",
        "import autocti.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load the CTI dataset 'dataset_1d/simple' 'from .fits files, which is the dataset we will use to perform CTI modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"dataset_1d\", dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Shape__\n",
        "\n",
        "The 1D shape of each 1D dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "shape_native = (200,)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regions__\n",
        "\n",
        "The locations of the prescan and overscan on the 1D data, which is used to visualize the 1D CTI dataset during the \n",
        "model-fit and customize aspects of the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prescan = ac.Region1D((0, 10))\n",
        "overscan = ac.Region1D((190, 200))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the charge regions on the 1D CTI Dataset, corresponding to where a signal is contained that has its electrons \n",
        "captured and trailed by CTI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "region_list = [(10, 20)]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Normalizations__\n",
        "\n",
        "We require the normalization of the charge in every CTI dataset, as the names of the files are tagged with this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "norm_list = [100, 5000, 25000, 200000]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Layout__\n",
        "\n",
        "We use the regions and norm_list above to create the `Layout1D` of every 1D CTI dataset we fit. This is used \n",
        "for visualizing the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "layout_list = [\n",
        "    ac.Layout1D(\n",
        "        shape_1d=shape_native,\n",
        "        region_list=region_list,\n",
        "        prescan=prescan,\n",
        "        overscan=overscan,\n",
        "    )\n",
        "    for norm in norm_list\n",
        "]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "We now load every cti-dataset, including a noise-map and pre-cti data containing the data before read-out and\n",
        "therefore without CTI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_list = [\n",
        "    ac.Dataset1D.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"data.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"noise_map.fits\"),\n",
        "        pre_cti_data_path=path.join(\n",
        "            dataset_path, f\"norm_{int(norm)}\", \"pre_cti_data.fits\"\n",
        "        ),\n",
        "        layout=layout,\n",
        "        pixel_scales=0.1,\n",
        "    )\n",
        "    for layout, norm in zip(layout_list, norm_list)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Clocker__\n",
        "\n",
        "The `Clocker1D` object models the read-out process of every 1D dataset as if it were clocked out on a real CCD. This \n",
        "includes the addition of CTI. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clocker = ac.Clocker1D(express=5)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__CTI Model__\n",
        "\n",
        "We now compose the CTI model we will use to correct CTI from the data.\n",
        "\n",
        "In this example, the true CTI model used to simulate the data is specified below. The `results` and `database` \n",
        "packages have tutorials showing how to directly use the results of a CTI calibration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "trap_0 = ac.TrapInstantCapture(density=0.13, release_timescale=1.25)\n",
        "trap_1 = ac.TrapInstantCapture(density=0.25, release_timescale=4.4)\n",
        "trap_list = [trap_0, trap_1]\n",
        "\n",
        "ccd = ac.CCDPhase(well_fill_power=0.58, well_notch_depth=0.0, full_well_depth=200000.0)\n",
        "\n",
        "cti = ac.CTI1D(trap_list=trap_list, ccd=ccd)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Correction__\n",
        "\n",
        "We use the CTI model and clocker to perform the CTI correction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_corrected_1d_list = [\n",
        "    clocker.remove_cti(data=dataset.data, cti=cti) for dataset in dataset_list\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "Output the corrected image to the dataset path as a .png file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for data_corrected_1d, norm in zip(data_corrected_1d_list, norm_list):\n",
        "    mat_plot = aplt.MatPlot1D(\n",
        "        output=aplt.Output(\n",
        "            path=path.join(dataset_path, \"correction\", f\"norm_{int(norm)}\"),\n",
        "            filename=f\"data_corrected\",\n",
        "            format=\"png\",\n",
        "        )\n",
        "    )\n",
        "\n",
        "    array_1d_plotter = aplt.Array1DPlotter(y=data_corrected_1d, mat_plot_1d=mat_plot)\n",
        "    array_1d_plotter.figure_1d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output the image, noise-map and pre CTI image of the dataset to .fits files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "[\n",
        "    data_corrected_1d.output_to_fits(\n",
        "        file_path=path.join(\n",
        "            dataset_path, \"correction\", f\"norm_{int(norm)}\", f\"data_corrected.fits\"\n",
        "        ),\n",
        "        overwrite=True,\n",
        "    )\n",
        "    for data_corrected_1d, norm in zip(data_corrected_1d_list, norm_list)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__CTI json__\n",
        "\n",
        "Save the `Clocker2D` and `CTI2D` in the dataset folder as a .json file, ensuring the traps and CCD settings used to\n",
        "perform the correction are safely stored and available to check how the dataset was simulated in the future. \n",
        "\n",
        "This can be loaded via the method `CTI2D.from_json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ac.output_to_json(\n",
        "    obj=cti,\n",
        "    file_path=path.join(dataset_path, \"cti_correction.json\"),\n",
        ")\n",
        "ac.output_to_json(\n",
        "    obj=clocker,\n",
        "    file_path=path.join(dataset_path, \"clocker_correction.json\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}