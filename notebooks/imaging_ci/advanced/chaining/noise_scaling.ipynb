{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chaining: Noise Scaling\n",
        "=======================\n",
        "\n",
        "In this script, we chain two searches to fit `ImagingCI` with a CTI model where:\n",
        "\n",
        " - The final CTI model consists of two parallel `Trap` species.\n",
        " - The `CCD` volume filling is a simple parameterization with just a `well_fill_power` parameter.\n",
        "\n",
        "The simulated data has Poisson trap densities, which lead to large chi-squareds in our model fit due to the\n",
        "assumption of a single average trap density. Our second search therefore applies noise scaling, which increases\n",
        "the noise in locations of the fit with large chi-squareds to down weight their contribution to the model inference.\n",
        "\n",
        "The two searches break down as follows:\n",
        "\n",
        " 1) Model CTI using a single parallel trap species and volume filling parameterization.\n",
        " 2) Model CTI using the same model, but with noise scaling applied.\n",
        "\n",
        "__Why Chain?__\n",
        "\n",
        "The noise scaling maps must preferentially scale columns of data where there are large chi-squareds. These are\n",
        "the columns whose densities are larger outliers.\n",
        "\n",
        "In order to scale the nosie in this way, we therefore require an intiial fit that gives us the initial chi\n",
        "squared map used to inform noise scaling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import copy\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autocti as ac\n",
        "import autocti.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__ \n",
        "\n",
        "The paths pointing to the dataset we will use for CTI modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging_ci\", \"poisson\", dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Layout__\n",
        "\n",
        "Set up the 2D layout of the charge injection data and load it using this layout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "shape_native = (2000, 100)\n",
        "\n",
        "parallel_overscan = ac.Region2D((1980, 2000, 5, 95))\n",
        "serial_prescan = ac.Region2D((0, 2000, 0, 5))\n",
        "serial_overscan = ac.Region2D((0, 1980, 95, 100))\n",
        "\n",
        "region_list = [\n",
        "    (0, 200, serial_prescan[3], serial_overscan[2]),\n",
        "    (400, 600, serial_prescan[3], serial_overscan[2]),\n",
        "    (800, 1000, serial_prescan[3], serial_overscan[2]),\n",
        "    (1200, 1400, serial_prescan[3], serial_overscan[2]),\n",
        "    (1600, 1800, serial_prescan[3], serial_overscan[2]),\n",
        "]\n",
        "\n",
        "norm_list = [100, 200000]\n",
        "\n",
        "total_datasets = len(norm_list)\n",
        "\n",
        "layout_list = [\n",
        "    ac.Layout2DCI(\n",
        "        shape_2d=shape_native,\n",
        "        region_list=region_list,\n",
        "        parallel_overscan=parallel_overscan,\n",
        "        serial_prescan=serial_prescan,\n",
        "        serial_overscan=serial_overscan,\n",
        "    )\n",
        "    for i in range(total_datasets)\n",
        "]\n",
        "\n",
        "dataset_list = [\n",
        "    ac.ImagingCI.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"data.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"norm_{int(norm)}\", \"noise_map.fits\"),\n",
        "        pre_cti_data_path=path.join(\n",
        "            dataset_path, f\"norm_{int(norm)}\", \"pre_cti_data.fits\"\n",
        "        ),\n",
        "        layout=layout,\n",
        "        pixel_scales=0.1,\n",
        "    )\n",
        "    for layout, norm in zip(layout_list, norm_list)\n",
        "]\n",
        "\n",
        "dataset_plotter = aplt.ImagingCIPlotter(dataset=dataset_list[0])\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "The path the results of all chained searches are output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path_prefix = path.join(\"imaging_ci\", \"chaining\", \"noise_scaling\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Full__\n",
        "\n",
        "Below, we are going to mask the data and extract a subset of the imaging data, which we will fit with a CTI model. \n",
        "\n",
        "Default visualization will be performed on this masked and extracted data, therefore not giving a complete picture of\n",
        "how the model fits the overall data.\n",
        "\n",
        "We create a deepcopy of the imaging data before masking / extraction, and visualization of the model-fit will also \n",
        "be performed on this full dataset, giving a complete  picture of the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_ci_full_list = copy.deepcopy(dataset_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We apply a 2D mask which removes the FPR (e.g. all 200 pixels where the charge injection is performed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = ac.Mask2D.all_false(\n",
        "    shape_native=dataset_list[0].shape_native,\n",
        "    pixel_scales=dataset_list[0].pixel_scales,\n",
        ")\n",
        "\n",
        "mask = ac.Mask2D.masked_fpr_and_eper_from(\n",
        "    mask=mask,\n",
        "    layout=dataset_list[0].layout,\n",
        "    settings=ac.SettingsMask2D(parallel_fpr_pixels=(0, 200)),\n",
        "    pixel_scales=dataset_list[0].pixel_scales,\n",
        ")\n",
        "\n",
        "dataset_list = [dataset.apply_mask(mask=mask) for dataset in dataset_list]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Clocking__\n",
        "\n",
        "The `Clocker` models the CCD read-out, including CTI. \n",
        "\n",
        "For parallel clocking, we use 'charge injection mode' which transfers the charge of every pixel over the full CCD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clocker = ac.Clocker2D(\n",
        "    parallel_express=5, parallel_roe=ac.ROEChargeInjection(), parallel_fast_mode=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 1)__\n",
        "\n",
        "In Search 1 we fit a CTI model with:\n",
        "\n",
        " - One parallel `TrapInstantCapture`'s species [2 parameters].\n",
        "\n",
        " - A simple `CCD` volume filling parametrization with fixed notch depth and capacity [1 parameter].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parallel_trap_0 = af.Model(ac.TrapInstantCapture)\n",
        "parallel_trap_1 = af.Model(ac.TrapInstantCapture)\n",
        "\n",
        "parallel_trap_0.add_assertion(\n",
        "    parallel_trap_0.release_timescale < parallel_trap_1.release_timescale\n",
        ")\n",
        "parallel_trap_list = [parallel_trap_0, parallel_trap_1]\n",
        "\n",
        "parallel_ccd = af.Model(ac.CCDPhase)\n",
        "parallel_ccd.well_notch_depth = 0.0\n",
        "parallel_ccd.full_well_depth = 200000.0\n",
        "\n",
        "model_1 = af.Collection(\n",
        "    cti=af.Model(\n",
        "        ac.CTI2D, parallel_trap_list=parallel_trap_list, parallel_ccd=parallel_ccd\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_1.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings + Search + Analysis + Model-Fit (Search 1)__\n",
        "\n",
        "We now create the non-linear search, analysis and perform the model-fit using this model.\n",
        "\n",
        "You may wish to inspect the results of the search 1 model-fit to ensure a fast non-linear search has been provided that \n",
        "provides a reasonably accurate CTI model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_1_list = [\n",
        "    ac.AnalysisImagingCI(dataset=dataset, clocker=clocker) for dataset in dataset_list\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By summing this list of analysis objects, we create an overall `Analysis` which we can use to fit the CTI model, where:\n",
        "\n",
        " - The log likelihood function of this summed analysis class is the sum of the log likelihood functions of each \n",
        " individual analysis object.\n",
        "\n",
        " - The summing process ensures that tasks such as outputting results to hard-disk, visualization, etc use a \n",
        " structure that separates each analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_1 = sum(analysis_1_list)\n",
        "analysis_1.n_cores = 1\n",
        "\n",
        "search_1 = af.Nautilus(\n",
        "    path_prefix=path_prefix, name=\"search[1]_species[x1]\", n_live=100\n",
        ")\n",
        "\n",
        "result_1_list = search_1.fit(model=model_1, analysis=analysis_1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Map Scaling__\n",
        "\n",
        "We now set each charge injection imaging dataset with a noise scaling map, where this noise-scaling map is the\n",
        "chi-squared values of different regions of the image.\n",
        "\n",
        "For this script we only perform noise map scaling in one region of the data, the parallel EPERs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "[\n",
        "    imaging_ci.set_noise_scaling_map_dict(\n",
        "        noise_scaling_map_dict=result_1.noise_scaling_map_dict\n",
        "    )\n",
        "    for dataset, result_1 in zip(dataset_list, result_1_list)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 2)__\n",
        "\n",
        "We use the results of search 1 to create the model fitted in search 2, with:\n",
        "\n",
        " - a free parameter in every analysis which fits the noise scaling in the parallel EPERs.\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_2 = af.Collection(\n",
        "    cti=af.Model(\n",
        "        ac.CTI2D,\n",
        "        parallel_trap_list=result_1_list.instance.cti.parallel_trap_list,\n",
        "        parallel_ccd=result_1_list.instance.cti.parallel_ccd,\n",
        "    ),\n",
        "    hyper_noise=af.Model(\n",
        "        ac.HyperCINoiseCollection,\n",
        "        regions_ci=ac.HyperCINoiseScalar,\n",
        "        parallel_eper=ac.HyperCINoiseScalar,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings + Search + Analysis + Model-Fit (Search 2)__\n",
        "\n",
        "We now create the non-linear search, analysis and perform the model-fit using this model.\n",
        "\n",
        "Whereas in the previous search we reduced run-times by trimming the data to just 5 columns, when we perform search\n",
        "chaining we can increase this in the second search. The run times will slow down, but the model we infer will be\n",
        "more accurate and precise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_2_list = [\n",
        "    ac.AnalysisImagingCI(dataset=dataset, clocker=clocker) for dataset in dataset_list\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By summing this list of analysis objects, we create an overall `Analysis` which we can use to fit the CTI model, where:\n",
        "\n",
        " - The log likelihood function of this summed analysis class is the sum of the log likelihood functions of each \n",
        " individual analysis object.\n",
        "\n",
        " - The summing process ensures that tasks such as outputting results to hard-disk, visualization, etc use a \n",
        " structure that separates each analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_2 = sum(analysis_2_list)\n",
        "analysis_2.n_cores = 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make noise map scaling parameter free across every dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_2 = analysis_2.with_free_parameters(\n",
        "    model_2.hyper_noise.regions_ci, model_2.hyper_noise.parallel_eper\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model, including how parameters and priors were passed from `result_1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_2.info)\n",
        "\n",
        "search_2 = af.Nautilus(\n",
        "    path_prefix=path_prefix, name=\"search[2]_species[x2]\", n_live=100\n",
        ")\n",
        "\n",
        "# result_2_list = search_2.fit(model=model_2, analysis=analysis_2)\n",
        "\n",
        "result_2_list = search_2.fit_sequential(model=model_2, analysis=analysis_2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 3)__\n",
        "\n",
        "We use the results of search 1 and 2 to create the model fitted in search 3, with:\n",
        "\n",
        " - Two parallel `TrapInstantCapture`'s species [4 parameters: prior on density initialized from search 1].\n",
        "\n",
        " - A simple `CCD` volume filling parametrization with fixed notch depth and capacity [1 parameter: priors initialized \n",
        " from search 1].\n",
        " \n",
        " - The noise map scaling applied.\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parallel_trap_0 = af.Model(ac.TrapInstantCapture)\n",
        "parallel_trap_1 = af.Model(ac.TrapInstantCapture)\n",
        "parallel_trap_list = [parallel_trap_0, parallel_trap_1]\n",
        "\n",
        "parallel_ccd = af.Model(ac.CCDPhase)\n",
        "parallel_ccd.well_notch_depth = 0.0\n",
        "parallel_ccd.full_well_depth = 200000.0\n",
        "\n",
        "model_3 = af.Collection(\n",
        "    cti=af.Model(\n",
        "        ac.CTI2D, parallel_trap_list=parallel_trap_list, parallel_ccd=parallel_ccd\n",
        "    ),\n",
        "    hyper_noise=af.Model(\n",
        "        ac.HyperCINoiseCollection,\n",
        "        regions_ci=ac.HyperCINoiseScalar,\n",
        "        parallel_eper=ac.HyperCINoiseScalar,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model, including how parameters and priors were passed from `result_1` and `result_2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_3.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings + Search + Analysis + Model-Fit (Search 3)__\n",
        "\n",
        "We now create the non-linear search, analysis and perform the model-fit using this model.\n",
        "\n",
        "Whereas in the previous search we reduced run-times by trimming the data to just 5 columns, when we perform search\n",
        "chaining we can increase this in the second search. The run times will slow down, but the model we infer will be\n",
        "more accurate and precise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_3_list = [\n",
        "    ac.AnalysisImagingCI(dataset=dataset, clocker=clocker) for dataset in dataset_list\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By summing this list of analysis objects, we create an overall `Analysis` which we can use to fit the CTI model, where:\n",
        "\n",
        " - The log likelihood function of this summed analysis class is the sum of the log likelihood functions of each \n",
        " individual analysis object.\n",
        "\n",
        " - The summing process ensures that tasks such as outputting results to hard-disk, visualization, etc use a \n",
        " structure that separates each analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_3 = sum(analysis_3_list)\n",
        "analysis_3.n_cores = 1\n",
        "\n",
        "analysis_3 = analysis_3.with_free_parameters()\n",
        "\n",
        "search_3 = af.Nautilus(\n",
        "    path_prefix=path_prefix, name=\"search[3]_species[x2]\", n_live=100\n",
        ")\n",
        "\n",
        "result_3_list = search_3.fit(model=model_3, analysis=analysis_3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "In this example, we passed used prior passing to initialize a CTI model with multiple trap species with a sensible\n",
        "prior for the total density of trap_list based on a fit using a single species. We also pass information on the CCD volume\n",
        "filling behaviour.\n",
        "\n",
        "__Pipelines__\n",
        "\n",
        "Advanced search chaining uses `pipelines` that chain together multiple searches to perform complex CTI modeling in a \n",
        "robust and efficient way. \n",
        "\n",
        "The following example pipelines fits a two trap species CTI model, using the same approach demonstrated in this script \n",
        "of first fitting a single species:\n",
        "\n",
        " `autocti_workspace/imaging/chaining/pipelines/parallel.py`\n",
        " `autocti_workspace/imaging/chaining/pipelines/serial.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}